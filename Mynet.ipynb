{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Mynet.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "colab_type": "code",
        "id": "c7B0iBdLIkko",
        "outputId": "95e429ab-1a5f-4e45-a504-afb85c7d711c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/content\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.utils.data as data\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "from torch.nn import Module\n",
        "from torchvision import transforms\n",
        "from torch.utils.data import Dataset\n",
        "from torch.utils.data import DataLoader\n",
        "from tqdm import tqdm\n",
        "import torchvision\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import time\n",
        "import os\n",
        "import sys\n",
        "import zipfile\n",
        "import csv\n",
        "from collections import OrderedDict\n",
        "from PIL import Image\n",
        "\n",
        "BATCH_SIZE = 40   \n",
        "\n",
        "print(os.getcwd()) #获取当前工作目录路径\n",
        "\n",
        "#解压缩文件\n",
        "extracting = zipfile.ZipFile('train_val.zip')\n",
        "extracting.extractall()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "lVtdxhBKAMvw"
      },
      "outputs": [],
      "source": [
        "def rotation(array, angle):\n",
        "    X = np.rot90(array, angle[0], axes=(0, 1))  # rotate in X-axis\n",
        "    Y = np.rot90(X, angle[1], axes=(0, 2))  # rotate in Y'-axis\n",
        "    Z = np.rot90(Y, angle[2], axes=(1, 2))  # rotate in Z\"-axis\n",
        "    return Z\n",
        "\n",
        "\n",
        "def reflection(array, axis):\n",
        "    if axis != -1:\n",
        "        ref = np.flip(array, axis)\n",
        "    else:\n",
        "        ref = np.copy(array)\n",
        "    return ref\n",
        "\n",
        "\n",
        "def crop(array, zyx, dhw):\n",
        "    cropped = array[zyx - dhw // 2:zyx + dhw // 2,\n",
        "             zyx - dhw // 2:zyx + dhw // 2,\n",
        "             zyx - dhw // 2:zyx + dhw // 2]\n",
        "    return cropped\n",
        "\n",
        "# 加入旋转翻折等操作的数据处理\n",
        "class Transform1(object):\n",
        "    def __init__(self, size):\n",
        "        self.size = size\n",
        "    def __call__(self, sample):\n",
        "        image = sample['image']\n",
        "        label = sample['label']\n",
        "        # shape = image.shape\n",
        "        arr_ret = crop(image, 50, self.size)\n",
        "        angle = np.random.randint(4, size=3)\n",
        "        arr_ret = rotation(arr_ret, angle=angle)\n",
        "        axis = np.random.randint(4) - 1\n",
        "        arr_ret = reflection(arr_ret, axis=axis)\n",
        "        arr_ret = np.expand_dims(arr_ret, axis=0)\n",
        "        arr_ret = 2*arr_ret/255-1\n",
        "        return {'image': (torch.from_numpy(arr_ret)).float(),\n",
        "             'label': torch.tensor(label)}\n",
        "\n",
        "# 简单数据处理\n",
        "class Transform2(object):\n",
        "    def __init__(self, size):\n",
        "        self.size = size\n",
        "    def __call__(self, sample):\n",
        "        image = sample['image']\n",
        "        label = sample['label']\n",
        "        image = 2*image/255-1\n",
        "        image = crop(image, 50, self.size)\n",
        "        image = image[np.newaxis, ...] \n",
        "        return {'image': (torch.from_numpy(image)).float(),\n",
        "             'label': torch.tensor(label)}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "QsxYxTeqHjSY"
      },
      "outputs": [],
      "source": [
        "# 定义TrainDataset类， 继承Dataset, 重写抽象方法：__len()__, __getitem()__\n",
        "class TrainDataset(Dataset):\n",
        "\n",
        "    def __init__(self, root, names_file, crop_size=32, transform=None):\n",
        "        self.root = root\n",
        "        self.names_file = names_file\n",
        "        self.transform = transform\n",
        "        self.size = 0\n",
        "        self.crop_size = crop_size\n",
        "        self.names_list = []\n",
        "\n",
        "        if not os.path.isfile(self.names_file):\n",
        "            print(self.names_file + 'does not exist!')\n",
        "        file = open(self.names_file)\n",
        "        next(file)\n",
        "        for f in file:\n",
        "            self.names_list.append(f)\n",
        "            self.size += 1\n",
        "\n",
        "    def __len__(self):\n",
        "        return self.size\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        image_path = self.names_list[idx].split(',')[0]\n",
        "        data = np.load(os.path.join(self.root, '%s.npz' % image_path))\n",
        "        voxel = data['voxel']\n",
        "        label = int(self.names_list[idx].split(',')[1])\n",
        "\n",
        "        sample = {'image': voxel, 'label': label}\n",
        "        if self.transform:\n",
        "            sample = self.transform(sample)\n",
        "\n",
        "        return sample\n",
        "\n",
        "# 变换ToTensor\n",
        "class ToTensor(object):\n",
        "    def __call__(self, sample):\n",
        "        return {'image': torch.from_numpy(sample['image']),\n",
        "             'label': torch.tensor(sample['label'])}\n",
        "\n",
        "train_dataset = TrainDataset(root='train_val', names_file='train1.csv',transform=Transform2(32))\n",
        "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=0,drop_last=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "t7Cw_tTuR7EE"
      },
      "outputs": [],
      "source": [
        "class FeatureBlock(nn.Sequential):\n",
        "    def __init__(self, input_channels, output_channels):\n",
        "        super(FeatureBlock, self).__init__()\n",
        "\n",
        "        self.input_channels = input_channels\n",
        "        self.output_channels = output_channels\n",
        "\n",
        "        # add_module:在现有model中增添子module\n",
        "        self.add_module('conv0', nn.Conv3d(input_channels, output_channels, kernel_size=3, stride=1, padding=0, bias=False)),\n",
        "        self.add_module('norm0', nn.BatchNorm3d(output_channels)),\n",
        "        self.add_module('relu0', nn.ReLU(inplace=True))\n",
        "\n",
        "class Bottleneck(nn.Sequential):\n",
        "    def __init__(self, in_channels, out_channels):\n",
        "        super(Bottleneck, self).__init__()\n",
        "\n",
        "        self.in_channels = in_channels\n",
        "        self.out_channels = out_channels\n",
        "\n",
        "        self.add_module('conv', nn.Conv3d(in_channels, out_channels, kernel_size=1, bias=False))\n",
        "        self.add_module('norm', nn.BatchNorm3d(num_features=out_channels))\n",
        "        self.add_module('relu', nn.ReLU(inplace=True))\n",
        "\n",
        "class DenseLayer(nn.Sequential):\n",
        "    def __init__(self, input_channels, growth_rate, bn_size, bottleneck_ratio, drop_rate):   \n",
        "        super(DenseLayer, self).__init__()\n",
        "        self.add_module('norm1', nn.BatchNorm3d(input_channels)),\n",
        "        self.add_module('relu1', nn.ReLU(inplace=True)),\n",
        "        self.add_module('conv1', nn.Conv3d(input_channels, bn_size*growth_rate, kernel_size=1, stride=1, bias=False)),\n",
        "        self.add_module('norm2', nn.BatchNorm3d(bn_size * growth_rate)),\n",
        "        self.add_module('relu2', nn.ReLU(inplace=True)),\n",
        "\n",
        "        if bottleneck_ratio >0:\n",
        "          self.add_module('bottleneck', Bottleneck(bn_size * growth_rate, bottleneck_ratio * growth_rate))\n",
        "          in_channels = bottleneck_ratio * growth_rate\n",
        "        else:\n",
        "          in_channels = bn_size * growth_rate\n",
        "\n",
        "        self.add_module('conv2', nn.Conv3d(in_channels, growth_rate,kernel_size=3, stride=1, padding=1, bias=False)),\n",
        "\n",
        "        self.drop_rate = drop_rate\n",
        "\n",
        "    def forward(self, x):\n",
        "        new_features = super(DenseLayer, self).forward(x)\n",
        "        if self.drop_rate > 0:\n",
        "            new_features = F.dropout(new_features, p=self.drop_rate)\n",
        "        return torch.cat([x, new_features], 1)\n",
        "\n",
        "\n",
        "class DenseBlock(nn.Sequential):\n",
        "    def __init__(self, num_layers, input_channels, bn_size, growth_rate, bottleneck_ratio, drop_rate):\n",
        "        super(DenseBlock, self).__init__()\n",
        "        for i in range(num_layers):\n",
        "            layer = DenseLayer(input_channels + i * growth_rate, growth_rate, bn_size, bottleneck_ratio, drop_rate)\n",
        "            self.add_module('denselayer%d' % (i + 1), layer)\n",
        "\n",
        "\n",
        "class Transition(nn.Sequential):\n",
        "    def __init__(self, input_channels, output_channels):\n",
        "        super(Transition, self).__init__()\n",
        "        self.add_module('norm', nn.BatchNorm3d(input_channels))\n",
        "        self.add_module('relu', nn.ReLU(inplace=True))\n",
        "        self.add_module('conv', nn.Conv3d(input_channels, output_channels, kernel_size=1, stride=1, bias=False))\n",
        "        self.add_module('pool', nn.AvgPool3d(kernel_size=2, stride=2))\n",
        "\n",
        "class Flatten(Module):\n",
        "    def forward(self, x):\n",
        "        return x.view(x.size(0), -1)\n",
        "\n",
        "class Classification(nn.Sequential):\n",
        "\n",
        "    def __init__(self, input_channels, output_classes):\n",
        "        super(Classification, self).__init__()\n",
        "\n",
        "        self.input_channels = input_channels\n",
        "        self.output_classes = output_classes\n",
        "\n",
        "        self.add_module('norm', nn.BatchNorm3d(num_features=input_channels))\n",
        "        self.add_module('relu', nn.ReLU(inplace=True))\n",
        "        self.add_module('pool', nn.AvgPool3d(kernel_size=7, stride=1))\n",
        "        self.add_module('flatten', Flatten())\n",
        "        self.add_module('linear', nn.Linear(input_channels, output_classes))\n",
        "\n",
        "\n",
        "class DenseNet(nn.Module):\n",
        "    def __init__(self, growth_rate=16, block_config=(4, 4, 4),\n",
        "                 num_features=32, bn_size=4, bottleneck_ratio=0, drop_rate=0, num_classes=2):\n",
        "        super(DenseNet, self).__init__()\n",
        "        \n",
        "        # 预处理\n",
        "        self.features = FeatureBlock(input_channels=1,output_channels=num_features)\n",
        "\n",
        "        # DenseBlock模块\n",
        "        for i, num_layers in enumerate(block_config):\n",
        "            block = DenseBlock(num_layers=num_layers, input_channels=num_features,\n",
        "                       bn_size=bn_size, growth_rate=growth_rate, bottleneck_ratio=bottleneck_ratio, drop_rate=drop_rate)\n",
        "            self.features.add_module('denseblock%d' % i, block)\n",
        "            num_features = num_features + num_layers * growth_rate\n",
        "            if i != len(block_config) - 1:\n",
        "                trans = Transition(input_channels=num_features, output_channels=num_features // 2)\n",
        "                self.features.add_module('transition%d' % i, trans)\n",
        "                num_features = num_features // 2\n",
        "\n",
        "        self.classification = Classification(input_channels=num_features,output_classes=num_classes)\n",
        "\n",
        "        # 初始化\n",
        "        for i in self.modules():\n",
        "            if isinstance(i, nn.Conv3d):\n",
        "                nn.init.kaiming_normal_(i.weight)\n",
        "            elif isinstance(i, nn.BatchNorm3d):\n",
        "                nn.init.constant_(i.weight, 1)\n",
        "                nn.init.constant_(i.bias, 0)\n",
        "            elif isinstance(i, nn.Linear):\n",
        "                nn.init.constant_(i.bias, 0)\n",
        "\n",
        "    def forward(self, x):\n",
        "        features = self.features(x)\n",
        "        out = self.classification(features)\n",
        "        out = F.softmax(out, dim=1)\n",
        "        return out\n",
        "    \n",
        "    \n",
        "model=DenseNet()\n",
        "# 定义损失函数和优化器\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "# optimizer = optim.RMSprop(model.parameters(), lr=0.001, eps=1e-8,alpha=0.5)\n",
        "# optimizer = optim.SGD(model.parameters(), lr=0.01,momentum=0.5,weight_decay=1e-9)\n",
        "\n",
        "if torch.cuda.is_available():\n",
        "  model.cuda()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 730
        },
        "colab_type": "code",
        "id": "pcyD3nw5R8lN",
        "outputId": "f9e84eba-12ac-4c65-9fe1-ae1de19af943"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r  0%|          | 0/8 [00:00<?, ?it/s]/usr/local/lib/python3.6/dist-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type DenseNet. It won't be checked for correctness upon loading.\n",
            "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
            "/usr/local/lib/python3.6/dist-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type FeatureBlock. It won't be checked for correctness upon loading.\n",
            "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
            "/usr/local/lib/python3.6/dist-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type Conv3d. It won't be checked for correctness upon loading.\n",
            "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
            "/usr/local/lib/python3.6/dist-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type BatchNorm3d. It won't be checked for correctness upon loading.\n",
            "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
            "/usr/local/lib/python3.6/dist-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type ReLU. It won't be checked for correctness upon loading.\n",
            "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
            "/usr/local/lib/python3.6/dist-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type DenseBlock. It won't be checked for correctness upon loading.\n",
            "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
            "/usr/local/lib/python3.6/dist-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type DenseLayer. It won't be checked for correctness upon loading.\n",
            "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
            "/usr/local/lib/python3.6/dist-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type Transition. It won't be checked for correctness upon loading.\n",
            "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
            "/usr/local/lib/python3.6/dist-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type AvgPool3d. It won't be checked for correctness upon loading.\n",
            "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
            "/usr/local/lib/python3.6/dist-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type Classification. It won't be checked for correctness upon loading.\n",
            "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
            "/usr/local/lib/python3.6/dist-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type Flatten. It won't be checked for correctness upon loading.\n",
            "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
            "/usr/local/lib/python3.6/dist-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type Linear. It won't be checked for correctness upon loading.\n",
            "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
            "100%|██████████| 8/8 [00:06<00:00,  1.22it/s]\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:19: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  0%|          | 0/8 [00:00<?, ?it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy=0.93\n",
            "tensor(0.4185, device='cuda:0', grad_fn=<NllLossBackward>)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 8/8 [00:06<00:00,  1.20it/s]\n",
            "  0%|          | 0/8 [00:00<?, ?it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor(0.4101, device='cuda:0', grad_fn=<NllLossBackward>)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 8/8 [00:06<00:00,  1.19it/s]\n",
            "  0%|          | 0/8 [00:00<?, ?it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy=0.85\n",
            "tensor(0.4681, device='cuda:0', grad_fn=<NllLossBackward>)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 8/8 [00:06<00:00,  1.21it/s]\n",
            "  0%|          | 0/8 [00:00<?, ?it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor(0.5363, device='cuda:0', grad_fn=<NllLossBackward>)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 8/8 [00:06<00:00,  1.22it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy=0.88\n",
            "tensor(0.4768, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "Finished Training\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "for epoch in range(25):\n",
        "    model.train()\n",
        "    for i,data in enumerate(tqdm(train_loader),0):\n",
        "        # images,labels=data\n",
        "        images = data['image']\n",
        "        labels = data['label']\n",
        "        images = images.type(torch.FloatTensor)\n",
        "        images, labels = images.to(device), labels.to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        prediction=model(images)\n",
        "        loss=criterion(prediction,labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        torch.save(model, 'Model.pth')\n",
        "        torch.save(model.state_dict(), 'Model.pkl')\n",
        "    if epoch % 2 == 0:\n",
        "        model.eval() #模型做预测的时候不需要dropout,切换为eval()模式\n",
        "        prediction = torch.max(nn.functional.softmax(prediction),1)[1]  #转换为概率，后面的一是最大值索引，如果为0则返回最大值\n",
        "        pred_y = prediction.data.cpu().numpy().squeeze()\n",
        "        target_y = labels.data.cpu().numpy()\n",
        "        accuracy = sum(pred_y == target_y)/BATCH_SIZE #求准确率\n",
        "        print('Accuracy=%.2f' % accuracy)\n",
        "        model.train() #切换为训练模式\n",
        "    print(loss)\n",
        "print('Finished Training')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "colab_type": "code",
        "id": "b-Q6osyjR8xT",
        "outputId": "78d40274-7a84-423d-9c34-df28f3ff880d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training Accuary: 78.44 %\n"
          ]
        }
      ],
      "source": [
        "model.eval()\n",
        "correct_train = 0\n",
        "size_train = 0\n",
        "for i,Data in enumerate(train_loader,0):\n",
        "    data = Data['image']\n",
        "    target = Data['label']\n",
        "    # data,target=Data\n",
        "    data = data.type(torch.FloatTensor).cuda()\n",
        "    target = target.type(torch.FloatTensor).cuda()\n",
        "    output_train = model(data).cuda()\n",
        "    predict_train = torch.max(output_train.data,1)[1]\n",
        "    size_train +=target.size(0)\n",
        "    correct_train +=(predict_train==target).sum()\n",
        "print('Training Accuary: %0.2f' %(100.0*correct_train/size_train), '%')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "colab_type": "code",
        "id": "-MgOcBvuhMew",
        "outputId": "05ab28c8-99a5-424f-fcfc-fe60981a1db9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Evaluating Accuary: 62.50 %\n"
          ]
        }
      ],
      "source": [
        "model.eval()\n",
        "correct_train = 0\n",
        "size_train = 0\n",
        "for i,Data in enumerate(train2_loader,0):\n",
        "    data = Data['image']\n",
        "    target = Data['label']\n",
        "    # data,target=Data\n",
        "    data = data.type(torch.FloatTensor).cuda()\n",
        "    target = target.type(torch.FloatTensor).cuda()\n",
        "    output_train = model(data).cuda()\n",
        "    predict_train = torch.max(output_train.data,1)[1]\n",
        "    y = torch.softmax(output_train.data,1)[:,1]\n",
        "    if i==0:\n",
        "        prob = y\n",
        "        label = target\n",
        "    else:\n",
        "        prob=torch.cat((prob,y),dim=0)\n",
        "        label=torch.cat((label,target),dim=0)\n",
        "    size_train +=target.size(0)\n",
        "    correct_train +=(predict_train==target).sum()\n",
        "print('Evaluating Accuary: %0.2f' %(100.0*correct_train/size_train), '%')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 314
        },
        "colab_type": "code",
        "id": "Lt_DU_zh_Vdy",
        "outputId": "b47746f8-3d6c-42b3-b392-e49511f0aec8"
      },
      "outputs": [
        {
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYIAAAEXCAYAAACgUUN5AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\njvv/z42wm9JRB90AAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0.6483585858585861\n"
          ]
        }
      ],
      "source": [
        "#计算AUC面积\n",
        "def cal_rate(result, thres):\n",
        "    all_number = len(result[0])\n",
        "    # print all_number\n",
        "    TP = 0\n",
        "    FP = 0\n",
        "    FN = 0\n",
        "    TN = 0\n",
        "    for item in range(all_number):\n",
        "        disease = result[0][item]\n",
        "        if disease >= thres:\n",
        "            disease = 1\n",
        "        if disease == 1:\n",
        "            if result[1][item] == 1:\n",
        "                TP += 1\n",
        "            else:\n",
        "                FP += 1\n",
        "        else:\n",
        "            if result[1][item] == 0:\n",
        "                TN += 1\n",
        "            else:\n",
        "                FN += 1\n",
        "    # print TP+FP+TN+FN\n",
        "    accracy = float(TP+FP) / float(all_number)\n",
        "    if TP+FP == 0:\n",
        "        precision = 0\n",
        "    else:\n",
        "        precision = float(TP) / float(TP+FP)\n",
        "    TPR = float(TP) / float(TP+FN)\n",
        "    TNR = float(TN) / float(FP+TN)\n",
        "    FNR = float(FN) / float(TP+FN)\n",
        "    FPR = float(FP) / float(FP+TN)\n",
        "    # print accracy, precision, TPR, TNR, FNR, FPR\n",
        "    return accracy, precision, TPR, TNR, FNR, FPR\n",
        "\n",
        "\n",
        "#prob是样本正确率的array，label则是样本label的array\n",
        "\n",
        "threshold_vaule = sorted(prob)\n",
        "threshold_num = len(threshold_vaule)\n",
        "accracy_array = np.zeros(threshold_num)\n",
        "precision_array = np.zeros(threshold_num)\n",
        "TPR_array = np.zeros(threshold_num)\n",
        "TNR_array = np.zeros(threshold_num)\n",
        "FNR_array = np.zeros(threshold_num)\n",
        "FPR_array = np.zeros(threshold_num)\n",
        "# calculate all the rates\n",
        "\n",
        "for thres in range(threshold_num):\n",
        "    accracy, precision, TPR, TNR, FNR, FPR = cal_rate((prob,1-label), threshold_vaule[thres])\n",
        "    accracy_array[thres] = accracy\n",
        "    precision_array[thres] = precision\n",
        "    TPR_array[thres] = TPR\n",
        "    TNR_array[thres] = TNR\n",
        "    FNR_array[thres] = FNR\n",
        "    FPR_array[thres] = FPR\n",
        "\n",
        "AUC = np.trapz(TPR_array, FPR_array)\n",
        "threshold = np.argmin(abs(FNR_array - FPR_array))\n",
        "EER = (FNR_array[threshold]+FPR_array[threshold])/2\n",
        "plt.plot(FPR_array, TPR_array)\n",
        "plt.title('roc')\n",
        "plt.xlabel('FPR_array')\n",
        "plt.ylabel('TPR_array')\n",
        "plt.show()\n",
        "print(-AUC)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 305
        },
        "colab_type": "code",
        "id": "oh5lXlRBlLgM",
        "outputId": "e7b82556-eff3-4a76-a3bb-7a003e3c298e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Wed Dec 25 15:57:24 2019       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 440.44       Driver Version: 418.67       CUDA Version: 10.1     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla P100-PCIE...  Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   58C    P0    46W / 250W |  12705MiB / 16280MiB |      0%      Default |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                       GPU Memory |\n",
            "|  GPU       PID   Type   Process name                             Usage      |\n",
            "|=============================================================================|\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ],
      "source": [
        "!nvidia-smi"
      ]
    }
  ]
}
